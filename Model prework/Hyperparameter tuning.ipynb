{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "F1 scoring chosen for hyperparameter tuning in order to minimize false positives as well as false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import scipy.stats as stats\n",
    "import scipy.sparse\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, confusion_matrix, make_scorer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[i for i in range(1,51)],\n",
    "    'min_samples_leaf':[i for i in range(1,11)],\n",
    "    'n_estimators':[i for i in range(1,101)],\n",
    "    'class_weight': ['balanced'],\n",
    "    'max_features':[None,1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_impurity_decrease':[i for i in np.arange(0.0,0.35,0.05)],\n",
    "    'random_state': [42],\n",
    "    'n_jobs':[-1],\n",
    "    'verbose':[2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "Done.\n",
      "Engineering features...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Importing data...')\n",
    "data_path = r'../data/clean_df.csv.gz'\n",
    "df = pd.read_csv(data_path)\n",
    "print('Done.')\n",
    "\n",
    "print('Engineering features...')\n",
    "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
    "df['CRASH TIME'] = pd.to_datetime(df['CRASH TIME'])\n",
    "\n",
    "df['CASUALTIES?'] = 0\n",
    "mask = df['TOTAL PEDESTRIAN CASUALTIES'] != 0\n",
    "df.loc[mask, 'CASUALTIES?'] = 1\n",
    "df.loc[df['TOTAL PEDESTRIAN CASUALTIES'] != 1, ['TOTAL PEDESTRIAN CASUALTIES','CASUALTIES?']].sample(5)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan K-Means analysis\n",
      "# Clusters: 2\n",
      "    F1 score: 0.1541123002492303\n",
      "# Clusters: 3\n",
      "    F1 score: 0.1621875839828003\n",
      "# Clusters: 4\n",
      "    F1 score: 0.16244468182511826\n",
      "# Clusters: 5\n",
      "    F1 score: 0.15882567469000727\n",
      "# Clusters: 6\n",
      "    F1 score: 0.1605709471810278\n",
      "# Clusters: 7\n",
      "    F1 score: 0.16494845360824742\n",
      "# Clusters: 8\n",
      "    F1 score: 0.1634797405083484\n"
     ]
    }
   ],
   "source": [
    "boroughs = ['MANHATTAN','BROOKLYN','STATEN ISLAND','QUEENS','BRONX']\n",
    "subplots = [231,232,233,234,235]\n",
    "k_range = range(2,31)\n",
    "\n",
    "_ = plt.figure(figsize=(15,10))\n",
    "max_k = {}\n",
    "for space, current_borough in zip(subplots, boroughs):\n",
    "    print(f'{current_borough.title()} K-Means analysis')\n",
    "    borough = df[df['BOROUGH'] == current_borough]\n",
    "    f1_list = []\n",
    "    for i in k_range:\n",
    "        kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "        kmeans.fit(borough[['LATITUDE','LONGITUDE']].values)\n",
    "        df_clusters = pd.Series(kmeans.labels_)\n",
    "        cluster_dummies = pd.get_dummies(df_clusters)\n",
    "        X = scipy.sparse.csr_matrix(cluster_dummies)\n",
    "        y = borough['CASUALTIES?']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        log_reg = LogisticRegression(class_weight='balanced', max_iter=10_000)\n",
    "        log_reg.fit(X_train, y_train)\n",
    "        y_pred = log_reg.predict(X_test)\n",
    "        log_f1 = f1_score(y_test, y_pred)\n",
    "        print(f'# Clusters: {i}\\n    F1 score: {log_f1}')\n",
    "        f1_list.append(log_f1)\n",
    "    _ = plt.subplot(space)\n",
    "    _ = plt.plot(k_range, f1_list, 'k-')\n",
    "    _ = plt.grid()\n",
    "    _ = plt.xlabel(f'{current_borough.title()} Clusters', fontsize=12)\n",
    "    _ = plt.ylabel('f1 Score', fontsize=12)\n",
    "    _ = plt.xticks(k_range, rotation=60, ha='right', fontsize=6)\n",
    "    max_k[current_borough] = {\n",
    "                        'K':f1_list.index(max(f1_list))+2,\n",
    "                        'Score': max(f1_list)\n",
    "            }\n",
    "    _ = plt.subplot(236)\n",
    "    _ = plt.scatter(borough['LATITUDE'], borough['LONGITUDE'], alpha=0.4)\n",
    "    _ = plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1])\n",
    "_ = plt.savefig('K-Means borough analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in max_k:\n",
    "    print(f'{i}\\n    {max_k[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fitting K-means clusters...')\n",
    "k_clusters = []\n",
    "for i in max_k:\n",
    "    k_clusters.append(max_k[i]['K'])\n",
    "for n, borough in zip(k_clusters,boroughs):\n",
    "    print(f'    Calculating {borough.title()} clusters...')\n",
    "    \n",
    "    borough_accidents = df[df['BOROUGH'] == borough]\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    kmeans.fit(borough_accidents[['LATITUDE','LONGITUDE']].values)\n",
    "    \n",
    "    df.loc[df['BOROUGH'] == borough, f'{borough} CLUSTERS'] = kmeans.labels_\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating feature set...')\n",
    "borough_dummies = pd.get_dummies(df['BOROUGH'], sparse=True)\n",
    "borough_clusters = [borough+' CLUSTERS' for borough in boroughs]\n",
    "cluster_dummies = pd.get_dummies(df[borough_clusters].fillna(''), prefix='CLUSTER', sparse=True)\n",
    "pre_X = cluster_dummies.join(borough_dummies)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Splitting data...')\n",
    "X = scipy.sparse.csr_matrix(pre_X)\n",
    "y = df['CASUALTIES?']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = BayesSearchCV(estimator=RandomForestClassifier(), search_spaces=rf_params, scoring=make_scorer(f1_score), n_jobs=-1, return_train_score=True)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "cv_results = pd.DataFrame(cv.cv_results_)\n",
    "cv_results[['param_max_depth','param_n_estimators','mean_train_score','mean_test_score','mean_fit_time']].sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "print(f'{cv.best_params_}\\n{cv.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(**cv.best_params_)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(cv.best_params_)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export fitted tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = r'../Predictor tools/rf_params.pickle'\n",
    "with open(params_path, 'wb') as file:\n",
    "    pickle.dump(cv.best_params_, file)\n",
    "    \n",
    "with open(params_path, 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "    \n",
    "test == cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = r'../Predictor tools/k_clusters.pickle'\n",
    "with open(params_path, 'wb') as file:\n",
    "    pickle.dump(max_k, file)\n",
    "    \n",
    "with open(params_path, 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "\n",
    "test == max_k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
